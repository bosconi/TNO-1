package com.microsoft.research.tno.tools.datagen;

/*
 * Copyright 2014 Microsoft Corporation.
 */

import java.lang.*;
import java.lang.Integer;
import java.lang.RuntimeException;
import java.lang.String;
import java.lang.StringBuilder;
import java.lang.System;
import java.text.SimpleDateFormat;
import java.util.*;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.Locale;
import java.util.Map;
import java.util.Random;
import java.util.TimeZone;

/**
 * A simple utility class for generating test input data.
 * Has a main method so it can be run on the command line.
 */
public class DataGenTool {

    private static final String DEFAULT_FIRST_DOC_NUMBER = "0";
    private static final String DEFAULT_NUM_DOCS = "500";
    private static final String DEFAULT_NUM_TERMS = "5000";
    private static final String DEFAULT_NUM_SAMPLE_TERMS = "100";

    private static final String USAGE_STRING_SHORT =
            "Usage: java [SystemProperties] -jar datagen.jar ";

    // Declare as concrete type LinkedHashMap, and not the Map interface
    // since make use of semantics specific to the implementation
    // (iterates in insertion order).
    private static LinkedHashMap<String,String> s_fieldMetadata;

    enum FieldType {
        GUID, UNIQUE_GUID, STRING, INTEGER, DOUBLE, DATETIME, CONSTANT;
        static final Map<String,FieldType> s_StringToFieldTypeMap =
                new HashMap<String,FieldType>();
        static {
            for (FieldType ft : FieldType.values())
                s_StringToFieldTypeMap.put(ft.toString(), ft);
        }
    }

    static {
        // Example generated by Advisor ScaleExperimentation tool:
        // ccf02243-5f03-4619-902e-42e06186dad4,ManagementGroupName755,2e861aa9-f9d1-44c4-97c6-e1c0fa244b09,
        // ObjectFullName4178,03a7db24-d916-41bc-84d9-1c6b58fbe6f8,WorkflowName3311,WorkflowDisplayName3727,
        // e23b4d44-5b03-4d38-b6d8-b90411ba38ce,ObjectName4365,CounterName4418,InstanceName3888,2477.00,246.00,
        // 3551.00,3885.00,3222,2014-06-14T21:52:50.2980056Z,7f63bd5c-43d3-4b43-9b43-d5a3c34eef98,RootObjectName918,
        // ObjectDisplayName3134,ObjectType4135,SourceSystem229,8598c4ae-016e-4e1b-98fb-15439a1c2d03,PerfHourly

        s_fieldMetadata = new LinkedHashMap<String,String>();
        s_fieldMetadata.put("MG","guid");
        s_fieldMetadata.put("ManagementGroupName","string");
        s_fieldMetadata.put("ObjectId","guid");
        s_fieldMetadata.put("ObjectFullName","string");
        s_fieldMetadata.put("HealthServiceId","guid");
        s_fieldMetadata.put("WorkflowName","string");
        s_fieldMetadata.put("WorkflowDisplayName","string");
        s_fieldMetadata.put("RuleId","guid");
        s_fieldMetadata.put("ObjectName","string");
        s_fieldMetadata.put("CounterName","string");
        s_fieldMetadata.put("InstanceName","string");
        s_fieldMetadata.put("SampleValue","double");
        s_fieldMetadata.put("Min","double");
        s_fieldMetadata.put("Max","double");
        s_fieldMetadata.put("Percentile95","double");
        s_fieldMetadata.put("SampleCount","integer");
        s_fieldMetadata.put("TimeGenerated","datetime");
        s_fieldMetadata.put("TenantId","guid");
        s_fieldMetadata.put("RootObjectName","string");
        s_fieldMetadata.put("ObjectDisplayName","string");
        s_fieldMetadata.put("ObjectType","string");
        s_fieldMetadata.put("SourceSystem","string");
        s_fieldMetadata.put("Id","unique_guid");
        s_fieldMetadata.put("Type","constant:PerfHourly");
    }

    private Map<Integer, String> m_guidNumberToStringMap;
    private Map<String,Map<Integer, String>> m_fieldNameToTermNumberToTermStringMap;
    private Random m_termStringGenerator;
    private Random m_docNumberGenerator;

    // Input arguments.
    int m_firstDocNumber;
    int m_numDocs;
    int m_numTerms;
    String[] m_args;

    /**
     * See usage() for valid command line usage
     * @param args the params on the command line
     */
    public static void main(String[] args) {
        if (0 < args.length && ("-help".equals(args[0]) || "--help".equals(args[0]) || "-h".equals(args[0]))) {
            usage();
        } else {
            final DataGenTool t = parseArgsAndInit(args);
            t.execute();
        }
    }

    public void execute() {
        final long startTime = System.currentTimeMillis();

        outputColumnNames();

        int docCount = 0;
        while (docCount < m_numDocs ) {
            outputDoc(m_firstDocNumber + docCount);
            docCount++;
            if (docCount < m_numDocs) {
                appendOutput("\n");
            }
        }

        outputTermsToQuery();

        final long endTime = System.currentTimeMillis();
        //displayTiming(endTime - startTime);
    }

    private void outputColumnNames() {
        boolean firstEntry = true;
        for(Map.Entry<String, String> entry : s_fieldMetadata.entrySet()){
            if (!firstEntry) {
                appendOutput(",");
            }
            appendOutput(entry.getKey());
            firstEntry = false;
        }
        appendOutput("\n");
    }

    private void outputDoc(int docNum) {
        // For now at least, we use the same term number for all fields in a given document.
        // TODO: Review this choice.
        int termNumber = getTermNumber(docNum);

        int fieldIndex = 0;
        boolean firstEntry = true;
        for(Map.Entry<String, String> entry : s_fieldMetadata.entrySet()) {
            if (!firstEntry) {
                appendOutput(",");
            }
            appendOutput(fieldValue(docNum, fieldIndex, termNumber, entry.getKey(), entry.getValue()));
            fieldIndex++;
            firstEntry = false;
        }
    }

    private void outputTermsToQuery() {
        // TODO Make these properties configurable.
        final String fieldToQuery = "ManagementGroupName";
        final int fieldIndex = 1;
        final int numTermsToOutput = Integer.parseInt(DEFAULT_NUM_SAMPLE_TERMS);

        // For now, just pick requested number of terms from the set of all terms added to the
        // index at the point this latest set of docs has been ingested. Do not enforce uniqueness.
        //
        // Also for now, exploit the fact that each doc has a well-known term number associated
        // with it. So pick terms indirectly by picking random doc numbers up to the number of
        // docs at the point this latest set of docs has been ingested.
        // (i.e. Do not restrict the picked terms to those that have been used in the current
        // set of docs just generated - which could get from m_fieldNameToTermNumberToTermStringMap.get(fieldToQuery);)
        int highestDocNumber = m_firstDocNumber + m_numDocs;
        for (int i = 0; i < numTermsToOutput; i++) {
            int docNumber = m_docNumberGenerator.nextInt(highestDocNumber);
            int termNumber = getTermNumber(docNumber);
            String termString = getTermString(fieldToQuery, fieldIndex, termNumber);
            System.err.println(termString);
        }
    }

    private String fieldValue(int docNum, int fieldIndex, int termNumber, String fieldName, String fieldInfo) {
        int separatorIndex = fieldInfo.indexOf(':');
        String fieldTypeString = (separatorIndex == -1) ? fieldInfo : fieldInfo.substring(0, separatorIndex);
        FieldType fieldType = FieldType.s_StringToFieldTypeMap.get(fieldTypeString.toUpperCase());
        if (fieldType == null) {
            throw new RuntimeException("Unknown FieldType " + fieldTypeString);
        }
        switch(fieldType) {
            case GUID:
                return getReusedGUID(termNumber);
            case UNIQUE_GUID:
                return getUniqueGUID();
            case STRING:
                return getTermString(fieldName, fieldIndex, termNumber);
            case DOUBLE:
                return Double.toString((double)termNumber);
            case INTEGER:
                return Integer.toString(termNumber);
            case DATETIME:
                // TODO Implement generation time based on fixed start date and notional ingestion rate.
                Date date = new Date();
                //String ISO_FORMAT = "yyyy-MM-dd'T'HH:mm:ss.SSS zzz";
                String ISO_FORMAT = "yyyy-MM-dd'T'HH:mm:ss.SSS";
                SimpleDateFormat sdf = new SimpleDateFormat(ISO_FORMAT);
                TimeZone utc = TimeZone.getTimeZone("UTC");
                sdf.setTimeZone(utc);
                return sdf.format(date) + "Z";
            case CONSTANT:
                if (separatorIndex == -1) {
                    throw new RuntimeException("Constant field " + fieldName + " is missing constant value.");
                }
                String constant = fieldInfo.substring(separatorIndex+1);
                return constant;
            default:
                throw new RuntimeException("FieldType " + fieldTypeString + " needs field value implementation!");
        }
    }

    private String getReusedGUID(int guidNumber) {
        // TODO: Reuse GUIDs across invocations of the tool.

        String guidString = m_guidNumberToStringMap.get(guidNumber);
        if (guidString == null) {
            guidString = getUniqueGUID();
            m_guidNumberToStringMap.put(guidNumber, guidString);
        }
        return guidString;
    }

    private String getUniqueGUID() {
        return java.util.UUID.randomUUID().toString();
    }

    private int getTermNumber(int docNumber) {
        // TODO Implement different distributions. For now, just support round robin on doc number.
        return docNumber % m_numTerms;
    }

    private static final String s_alphabet = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";

    /**
     * Term strings have N random letters (upper and lower case) followed by the term number,
     * where N is the length of the field name.
     *
     * The random number generator used to produce the random letters is seeded with:
     *   (termNumber * number of fields in each document) + field index in document
     *
     * @param fieldName
     * @param fieldIndex
     * @param termNumber
     * @return
     */
    private String getTermString(String fieldName, int fieldIndex, int termNumber) {
        Map<Integer,String> termNumberToTermStringMap = m_fieldNameToTermNumberToTermStringMap.get(fieldName);
        if (termNumberToTermStringMap == null) {
            termNumberToTermStringMap = new HashMap<Integer,String>(m_numTerms);
            m_fieldNameToTermNumberToTermStringMap.put(fieldName, termNumberToTermStringMap);
        }
        String termString = termNumberToTermStringMap.get(termNumber);
        if (termString == null) {
            long termStringSeed = (termNumber * s_fieldMetadata.size()) + fieldIndex;
            m_termStringGenerator.setSeed(termStringSeed);
            int numRandomLetters = fieldName.length();
            StringBuilder sb = new StringBuilder(numRandomLetters);
            for (int i = 0; i < numRandomLetters; i++) {
                sb.append(s_alphabet.charAt(m_termStringGenerator.nextInt(52)));
            }
            termString = sb.toString() + "-" + Integer.toString(termNumber);
            termNumberToTermStringMap.put(termNumber, termString);
            // System.err.println("Adding " + fieldName + " " + termString);
        }
        return termString;
    }

    /**
     * Pretty prints the number of milliseconds taken to post the content to Solr
     * @param millis the time in milliseconds
     */
    private void displayTiming(long millis) {
        SimpleDateFormat df = new SimpleDateFormat("H:mm:ss.SSS", Locale.getDefault());
        df.setTimeZone(TimeZone.getTimeZone("UTC"));
        System.out.println("Time spent: "+df.format(new Date(millis)));
    }

    /**
     * Parses incoming arguments and system params and initializes the tool
     * @param args the incoming cmd line args
     * @return an instance of DataGenTool
     *
     * Note that currently all the arguments are Java system properties (-Dname=value)
     * This is a trick employed by the Solr posting tool, and is good enough for now.
     *   See solr-4.6.1/solr/core/src/java/org/apache/solr/util/SimplePostTool.java
     */
    protected static DataGenTool parseArgsAndInit(String[] args) {
        int firstDocNumber = Integer.parseInt(System.getProperty("firstDocNumber", DEFAULT_FIRST_DOC_NUMBER));
        if (firstDocNumber < 0) {
            usage();
            fatal("firstDocNumber must be 0 or greater.");
        }

        int numDocs = Integer.parseInt(System.getProperty("numDocs", DEFAULT_NUM_DOCS));
        if (numDocs < 1) {
            usage();
            fatal("numDocs must be 1 or greater.");
        }

        int numTerms = Integer.parseInt(System.getProperty("numTerms", DEFAULT_NUM_TERMS));
        if (numTerms < 1) {
            usage();
            fatal("numTerms must be 1 or greater.");
        }

        return new DataGenTool(firstDocNumber, numDocs, numTerms, args);
    }

    /**
     * Constructor which takes in all mandatory parameters for the tool to work.
     * Also see usage() for further explanation of the params.
     * @param firstDocNumber the offset of the first document to produce, in a larger space of docs
     * @param numDocs the number of documents to produce
     * @param numTerms the number of distinct terms to use
     * @param args a String[] of any additional arguments. Currently unused
     */
    public DataGenTool(int firstDocNumber, int numDocs, int numTerms, String[] args) {
        this.m_firstDocNumber = firstDocNumber;
        this.m_numDocs = numDocs;
        this.m_numTerms = numTerms;
        this.m_args = args;

        this.m_guidNumberToStringMap = new HashMap<Integer, String>(numTerms);
        this.m_fieldNameToTermNumberToTermStringMap =
                new HashMap<String, Map<Integer, String>>(s_fieldMetadata.size());

        // RNG for producing sequences of pseudo-random letters in term strings.
        // Seed the generator each time generate a term string.
        this.m_termStringGenerator = new Random();
        // RNG for producing sequence of doc numbers to pick terms for sample queries.
        // Seed the generator off of the first doc number in each use of the tool.
        this.m_docNumberGenerator = new Random(m_firstDocNumber);
    }

    public DataGenTool() {
        fatal("Must call constructor which initalizes mandatory parameters.");
    }

    private void appendOutput(String output) {
        System.out.print(output);
    }

    private static void info(String msg) {
        System.err.println(msg);
    }

    private static void fatal(String msg) {
        System.err.println("DataGenTool: FATAL: " + msg);
        System.exit(2);
    }

    //
    // USAGE
    //
    private static void usageShort() {
        System.out.println(USAGE_STRING_SHORT+"\n"+
                "       Please invoke with -h option for extended usage help.");
    }

    private static void usage() {
        System.out.println
                (USAGE_STRING_SHORT+"\n\n" +
                        "Supported System Properties and their defaults:\n"+
                        "  -DfirstDocNumber=<int greater than 0> (default=" + DEFAULT_FIRST_DOC_NUMBER + ")\n"+
                        "This is a simple command line tool for generating data to POST to a Solr server.\n"+
                        "Examples:\n"+
                        "  java -jar datagen.jar\n"+
                        "  java -DfirstDocNumber=501 -jar datagen.jar\n");
    }
}
